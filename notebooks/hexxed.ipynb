{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "294c8b28-272e-4c59-a5d0-edc476da2a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuronav.envs.hexxed_env import GridEnv, GridSize, GridObservation, GridOrientation\n",
    "from neuronav.envs.graph_env import GraphEnv, GraphObservation\n",
    "from neuronav.agents.td_agents import TDSR, TDQ\n",
    "from neuronav.agents.dyna_agents import DynaQ, DynaSR\n",
    "from neuronav.agents.mb_agents import MBV\n",
    "from neuronav.envs.grid_templates import GridTemplate\n",
    "from neuronav.envs.graph_templates import GraphTemplate\n",
    "from neuronav.utils import run_episode, softmax, plot_values_and_policy\n",
    "from neuronav.utils import run_episode, softmax, plot_values_and_policy\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "64f5d3b3-88d2-4716-ba93-7a7a442623ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "4\n",
      "3\n",
      "2\n",
      "1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 85 and the array at index 1 has size 128",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_32852\\1917179666.py\u001B[0m in \u001B[0;36m<cell line: 4>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      2\u001B[0m \u001B[0mobs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0menv\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mreset\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m      3\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m----> 4\u001B[1;33m \u001B[0menv\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrender\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;32m~\\Documents\\Hexxed\\hexxed-neuro-nav\\neuronav\\envs\\hexxed_env.py\u001B[0m in \u001B[0;36mrender\u001B[1;34m(self, provide)\u001B[0m\n\u001B[0;32m    331\u001B[0m             \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'foo1'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    332\u001B[0m             \u001B[0mimg_first\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrenderer\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mrender_frame\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 333\u001B[1;33m             \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'foo2'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    334\u001B[0m             \u001B[0mtop_down\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mcv\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mresize\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mimage\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m(\u001B[0m\u001B[1;36m128\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;36m128\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    335\u001B[0m             \u001B[0mprint\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;34m'foo3'\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32m<__array_function__ internals>\u001B[0m in \u001B[0;36mconcatenate\u001B[1;34m(*args, **kwargs)\u001B[0m\n",
      "\u001B[1;31mValueError\u001B[0m: all the input array dimensions for the concatenation axis must match exactly, but along dimension 0, the array at index 0 has size 85 and the array at index 1 has size 128"
     ]
    }
   ],
   "source": [
    "env = GridEnv(template=GridTemplate.hexxed, size = GridSize.hexxed, manual_collect = True, obs_type=GridObservation.rendered_3d)\n",
    "obs = env.reset()\n",
    "\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26740180-cb9e-4cf4-808c-27b9cc823fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.step(1)\n",
    "#env.agent_pos[0] = env.agent_pos[0]-1\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a282cf4-9e79-4aae-a73f-7a29192cf84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "\n",
    "def get_randomness():\n",
    "    agent_start = [12, random.randint(4, 9)]\n",
    "\n",
    "    rewards = {}\n",
    "    rwd_loc = random.randint(4, 9)\n",
    "    for i in reversed(range(1,6)):\n",
    "        reward = {(i, rwd_loc): i**2}\n",
    "        #print(i)\n",
    "        rewards.update(reward)\n",
    "    return agent_start , rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c946feaf-0e1e-4119-8a69-c03d67a54d9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6f91c5-4a9c-43f6-b488-d1f9656dd626",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24006109-c6ae-477a-a3ec-2d9a96d9a353",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = [0, 0, 0, 0,0, 0, 0,0,1,3]  # The optimal action sequence\n",
    "obs = env.reset()\n",
    "\n",
    "for idx, action in enumerate(actions):\n",
    "    obs, reward, done, _ = env.step(action)\n",
    "    env.render()\n",
    "    print(f\"Action: {action}, Reward: {reward}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1c2661-a1ac-4539-99cd-f565e64f29b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32423fae-4dfa-4472-b8da-d434791a665e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c5027b-cc3b-4599-937e-e9bc0e6d378a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b9888d-572e-4ae9-af61-e3af1d101272",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a98911-1f09-47a5-8d6d-a6f0e800646e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_episodes = 100\n",
    "num_steps = 13\n",
    "lr = 5e-2\n",
    "beta = 1e2\n",
    "\n",
    "agent = TDQ(env.state_size, env.action_space.n, poltype=\"softmax\", lr=lr, beta=beta)\n",
    "\n",
    "episode_steps = []\n",
    "for i in range(num_episodes):\n",
    "    done = False\n",
    "    steps = 0\n",
    "    objects = {\"rewards\": get_randomness()[1]}\n",
    "    obs = env.reset(objects = objects, agent_pos = get_randomness()[0])\n",
    "    #print('episode ',i)\n",
    "    while not done and steps < num_steps:\n",
    "        action = agent.sample_action(obs)\n",
    "        next_obs, reward, done, _ = env.step(action)\n",
    "        agent.update([obs, action, next_obs, reward, done])\n",
    "        obs = next_obs\n",
    "        steps += 1    \n",
    "        env.render()\n",
    "\n",
    "    episode_steps.append(steps)\n",
    "\n",
    "plt.plot(episode_steps)\n",
    "_ = plt.title(\"Length of episodes over the course of learning\")\n",
    "_ = plt.ylabel(\"Episode steps\")\n",
    "_ = plt.xlabel(\"Episode number\")\n",
    "plt.gcf().set_dpi(100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b536c5d4-24c9-40ef-aa1d-6066691baae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.imshow(agent.Q.mean(0).reshape(14, 14), cmap=\"RdBu\", vmin=-1, vmax=1)\n",
    "_ = plt.title(\"V(s) for each state in the maze\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef67855-c794-483b-ac4e-a36a1d2bd9b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_values_and_policy(agent, env, env.agent_start_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f036bc4-bf87-4945-9c99-68efbca13687",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d7715a-823a-4e1b-b299-a9dce749a58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "episode_steps = 8\n",
    "num_episodes = 10000\n",
    "beta = 1e2\n",
    "lr = 5e-2\n",
    "\n",
    "agent_q = TDQ(env.state_size, env.action_space.n, beta=beta, lr=lr)\n",
    "agent_dq = DynaQ(env.state_size, env.action_space.n, beta=beta, lr=lr)\n",
    "\n",
    "agents = {\"TDQ\": agent_q, \"DynaQ\": agent_dq}\n",
    "\n",
    "for agent_name in agents:\n",
    "    steps = []\n",
    "    for i in range(num_episodes):\n",
    "        agents[agent_name], step, _ = run_episode(\n",
    "            env, agents[agent_name], episode_steps\n",
    "        )\n",
    "        steps.append(step)\n",
    "    plt.plot(steps, label=agent_name)\n",
    "plt.legend()\n",
    "_ = plt.title(\"Steps to goal during learning process\")\n",
    "_ = plt.ylabel(\"Episode Steps\")\n",
    "_ = plt.xlabel(\"Episode Number\")\n",
    "plt.gcf().set_dpi(100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89ad8f94-df03-4701-aeec-e7e66d9d9091",
   "metadata": {},
   "outputs": [],
   "source": [
    "for agent in agents:\n",
    "    plot_values_and_policy(agents[agent], env, env.agent_start_pos, plot_title=agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24177172-fcff-43a3-8fd5-47c117db79ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
